
# Url处理

•100GB url 文件，使用 1GB 内存计算出出现次数 top100 的 url 和出现的次数

## 要求

1. 输入数据自己构造

2. 实现思路，测试，瓶颈分析，优化思路，优化前后结果对比，最好都能写出来

提示：

· 注意代码可读性，添加必要的注释（英文）

· 注意代码风格与规范，添加必要的单元测试和文档

· 注意异常处理，尝试优化性能

## 实现思路

主体思路：将Url先做hash，然后映射到小文件中。在每个小文件中使用堆找出Top100，再进行合并。

数据分析：将小文件的个数设置为500个，假设对于不同的Url来说，Hash值的分布是均匀的，则在每个小文件中，不同的Url的量级为0.2G，是内存可以存下的范围，可以对其进行次数统计。

算法流程：该算法主要分为4个部分

1. 读取数据，使用Hash函数对每个URL进行Hash，然后将Hash结果对500取模，将该Url映射到对应的小文件中。

2. 对于每个小文件来说，读取数据，使用哈希表来统计每个Url出现的次数。遍历一遍哈希表，将结果放入一个小根堆中，并维护堆的大小在100以内。

3. 将500个小根堆依次合并，并维护堆的大小在100以内。将堆中的数据输出。

4. 清除程序所创建的临时文件。

## 瓶颈分析和优化思路

1. 硬盘IO效率不高。可以使用fread直接把100MB的内容从文件中读取到内存，再进行字符串处理。

2. 为充分利用CPU多核运算的特性，可以使用多线程来加速。考虑到内存的使用情况，对每个文件的处理最多会占用0.2G，因此可以使用5个线程。

## 使用方式

假设url文件保存在data.txt文件中，其中格式为每行一个url。

运行如下命令，结果会输出到名为answer.txt文件中。

``` bash
make
./main
```

## 测试

### 10GB test

#### 使用fscanf读入 单线程：

part1: 420s &nbsp; part2: 700s &nbsp; part3-4: 2s以内 &nbsp; 共计18min左右

#### 使用fread加速读入 单线程：

part1: 340s &nbsp; part2: 450s &nbsp; part3-4: 2s以内 &nbsp; 共计13min左右

#### 使用fread加速读入 多线程：

part1: 340s &nbsp; part2（多线程）: 220s &nbsp; part3-4: 2s以内 &nbsp; 共计9min左右

#### 将优化后的程序和文件放到固态硬盘上运行

part1: 320s &nbsp; part2（多线程）: 40s &nbsp; part3-4: 2s以内 &nbsp; 共计6min

## 对极端测试数据的分析

如果数据极端倾斜，则会发生分到某一个临时文件的Url非常多，导致该文件非常大。

在程序读取文件时，并不会一次把整个文件读取到内存，而是一块一块的读取，因此大文件对IO来说影响不大。

在程序进行数量统计时，使用的数据结构为Hash表。相同Url在Hash表中所占用的空间仅为一组Key-Value对，并不会因其出现次数多而占用额外的空间。Hash表所占用的空间主要由其中不同的数据量来决定。在使用合理Hash函数的情况下，数据分布十分均匀，并且在内存存储的范围内，不会发生内存不足的情况。

在程序进程数量统计时，一个文件只能由一个线程处理，并不能使用多线程进行加速，可能会比纯随机数据有一定的效率差距。对于该问题，可以将该大文件分割成小文件，然后使用线程安全的Hash表来多线程进行数据统计。（未实现）

## 极端数据测试以及梯度级测试数据的构造

1. 数据倾斜情况。在该测试数据中，数据分布情况如下。

* 一条URL的出现频率为70%

* 其余URL均为随机数据

   测试目的：测试该程序对极端数据倾斜情况的解决效率。

   测试结果：part1:350s &nbsp; part2:50s &nbsp; (11GB数据) &nbsp; 经确认，输出结果中Top1即为该Url，且出现次数大约占总数的70%，符合预期的答案。

2. 梯度数据测试。在该测试数据中，数据分布情况如下：

* 1条URL的出现频率为30%

* 10条URL的出现频率为5%

* 100条URL的出现频率为0.1%

   测试目的：测试程序的运行时间，并且可以依靠构造数据特点对输出结果进行正确性判断。

   测试结果：part1:280s &nbsp; part2:40s &nbsp; (9.2GB数据)  &nbsp; 输出结果中Top100均为构造的Url，且出现次数与预期的相同。并且将构造的111个Url的出现次数排序，取出Top100，其与程序运行结果相同。

## 程序正确性测试与分析

1. 构造多个1G（内存可存放大小）的测试数据，编写一个直接使用Hashmap的程序统计并排序，将结果和本程序所输出的结果进行对比。此方法可以测试本程序在对于数据范围较小时的正确性。

2. 构造多个具有梯度的测试数据，如上的Test2。可直接由构造过程得出应该的结果，跟程序的输出结果进行对比。

3. 构造多个100G的测试数据，分割成小文件，使用Hashmap的程序统计。然后进行排序去重（可能是硬盘级别的排序），统计个数。将结果与程序输出个结果进行对比。此方法可以测试本程序在对于数据范围较大时的正确性。

## 优化效果

通过观察对于同测试数据所使用的不同时间，可以得出优化已经生效的结论。